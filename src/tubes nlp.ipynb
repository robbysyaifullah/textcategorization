{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from twitterscraper import query_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_of_tweets = query_tweets(\"Presiden OR Jokowi OR Pemerintah OR Menteri\", 100, poolsize=20)\n",
    "\n",
    "# #Or save the retrieved tweets to file:\n",
    "# file = open('output.txt','w')\n",
    "# for tweet in query_tweets(\"Presiden OR Jokowi OR Pemerintah OR Menteri\", 100):\n",
    "#     file.write(str(tweet.text.encode('utf-8')) +',\\n')\n",
    "# file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs, json, csv\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "\n",
    "import re, string\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitter Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitters = pd.read_csv(\"twitter_training.csv\")\n",
    "X = twitters['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@jokowi OK, Kami jg bangga. Tolong olahraga lain jg di perhatikan, Bgmn nasib PSSI? pemerintah jgn byk intervensi yg hrsnya di bina'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def removeURL(raw):\n",
    "    cleanr = re.compile(\"http?:\\/\\/.*[\\r\\n]*\")\n",
    "    cleantext = re.sub(cleanr, '', raw)\n",
    "    \n",
    "    return cleantext\n",
    "\n",
    "preprocess = []\n",
    "\n",
    "for i in range(len(X)):\n",
    "    preprocess.append(removeURL(X[i]))\n",
    "\n",
    "X = preprocess\n",
    "\n",
    "X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemWord(w):\n",
    "    words = word_tokenize(w)\n",
    "    factory = StemmerFactory()\n",
    "    stemmer = factory.create_stemmer()\n",
    "\n",
    "    sentence = ''\n",
    "    for word in words:\n",
    "        sentence += str(stemmer.stem(word)) + ' '\n",
    "    return sentence\n",
    "    \n",
    "process = []\n",
    "for i in range(len(X)):\n",
    "    process.append(stemWord(X[i]))\n",
    "    \n",
    "X = process \n",
    "X_dump = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pln tolong sih kasih jelas kenapa listrik mati trus  hari bisa 4x  elektronik kami bs rusak begini trus  plnlampung   jokowi ',\n",
       " 'assalamualaikum wr wb bapak presiden yth  jokowi kabar dr zakir naik akan datang ke indonesia  tolong siar di tv nasional ya pak  ',\n",
       " ' telkomcare pak  jokowi n pak  pak jk masyarakat internet sbnrnya sangat sayang mahal tarif ini  mohon dengar suara kami  ']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[26:29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1135 1135\n"
     ]
    }
   ],
   "source": [
    "count_vect = CountVectorizer()\n",
    "count_vect.fit(X)\n",
    "x = count_vect.transform(X)\n",
    "y = twitters['class']\n",
    "\n",
    "print(len(X), len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train, text_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score Logistic :  0.4810126582278481\n",
      "Accuracy Score Logistic :  0.7112676056338029\n",
      "Precision Score Logistic :  0.4\n",
      "Recall Score Logistic :  0.6031746031746031\n",
      "Mean Logistic Regression:  0.45550760008954255\n",
      "Std Logistic Regression:  0.04900601513172837\n",
      "284 63\n"
     ]
    }
   ],
   "source": [
    "log_regression = LogisticRegression()\n",
    "log_regression.fit(x_train, y_train)\n",
    "\n",
    "log_regression_pred = log_regression.predict(x_test)\n",
    "print('F1 Score Logistic : ', f1_score(log_regression_pred, y_test))\n",
    "print('Accuracy Score Logistic : ', accuracy_score(log_regression_pred, y_test))\n",
    "print('Precision Score Logistic : ', precision_score(log_regression_pred, y_test))\n",
    "print('Recall Score Logistic : ', recall_score(log_regression_pred, y_test))\n",
    "\n",
    "scores = cross_val_score(log_regression, x, y, scoring='f1', cv=5)\n",
    "\n",
    "print('Mean Logistic Regression: ', scores.mean())\n",
    "print('Std Logistic Regression: ', scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model/count_vectorizer.joblib']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(log_regression, 'model/classifier.joblib')\n",
    "joblib.dump(count_vect, 'model/count_vectorizer.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score Logistic :  0.40963855421686746\n",
      "Accuracy Score Logistic :  0.6549295774647887\n",
      "Precision Score Logistic :  0.35789473684210527\n",
      "Recall Score Logistic :  0.4788732394366197\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "tree.fit(x_train, y_train)\n",
    "\n",
    "tree_pred = tree.predict(x_test)\n",
    "print('F1 Score Logistic : ', f1_score(tree_pred, y_test))\n",
    "print('Accuracy Score Logistic : ', accuracy_score(tree_pred, y_test))\n",
    "print('Precision Score Logistic : ', precision_score(tree_pred, y_test))\n",
    "print('Recall Score Logistic : ', recall_score(tree_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score Logistic :  0.14678899082568805\n",
      "Accuracy Score Logistic :  0.6725352112676056\n",
      "Precision Score Logistic :  0.08421052631578947\n",
      "Recall Score Logistic :  0.5714285714285714\n"
     ]
    }
   ],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "neigh.fit(x_train, y_train)\n",
    "\n",
    "neigh_pred = neigh.predict(x_test)\n",
    "print('F1 Score Logistic : ', f1_score(neigh_pred, y_test))\n",
    "print('Accuracy Score Logistic : ', accuracy_score(neigh_pred, y_test))\n",
    "print('Precision Score Logistic : ', precision_score(neigh_pred, y_test))\n",
    "print('Recall Score Logistic : ', recall_score(neigh_pred, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
